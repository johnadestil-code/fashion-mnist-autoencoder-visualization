{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCwZjB6MAvO7"
      },
      "outputs": [],
      "source": [
        "# CSCI-485 — Assignment 3\n",
        "\n",
        "import random, numpy as np\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "SEED = 0\n",
        "EPOCHS = 15\n",
        "BATCH = 128\n",
        "LATS = (16, 32, 64)\n",
        "LR = 1e-3\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 1) data: [0,1], train/val/test\n",
        "tf = transforms.Compose([transforms.ToTensor()])\n",
        "def make_loaders():\n",
        "    train_full = datasets.FashionMNIST(\"./data\", train=True, download=True, transform=tf)\n",
        "    test_ds    = datasets.FashionMNIST(\"./data\", train=False, download=True, transform=tf)\n",
        "    n = len(train_full); n_val = int(0.1*n)\n",
        "    train_ds, val_ds = random_split(train_full, [n - n_val, n_val])\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=BATCH, shuffle=True),\n",
        "        DataLoader(val_ds,   batch_size=BATCH, shuffle=False),\n",
        "        DataLoader(test_ds,  batch_size=BATCH, shuffle=False),\n",
        "    )\n",
        "\n",
        "# 2) model: FC AE, ReLU hidden, Sigmoid output\n",
        "class AE(nn.Module):\n",
        "    def __init__(self, latent):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Flatten(), nn.Linear(784,256), nn.ReLU(), nn.Linear(256, latent)\n",
        "        )\n",
        "        self.dec = nn.Sequential(\n",
        "            nn.Linear(latent,256), nn.ReLU(), nn.Linear(256,784), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        z = self.enc(x); y = self.dec(z)\n",
        "        return y.view(-1,1,28,28), z\n",
        "\n",
        "crit = nn.MSELoss()\n",
        "\n",
        "def train_epoch(m, loader, opt):\n",
        "    m.train(); L=N=0.0\n",
        "    for x,_ in loader:\n",
        "        x=x.to(device); opt.zero_grad()\n",
        "        y,_=m(x); loss=crit(y,x); loss.backward(); opt.step()\n",
        "        L+=loss.item(); N+=1\n",
        "    return L/N\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(m, loader):\n",
        "    m.eval(); L=N=0.0\n",
        "    for x,_ in loader:\n",
        "        x=x.to(device); y,_=m(x); loss=crit(y,x)\n",
        "        L+=loss.item(); N+=1\n",
        "    return L/N\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_latents(m, loader, max_batches=8):\n",
        "    m.eval(); Z=[]; Y=[]; n=0\n",
        "    for x,y in loader:\n",
        "        x=x.to(device); _,z=m(x)\n",
        "        Z.append(z.cpu().numpy()); Y.append(y.numpy()); n+=1\n",
        "        if n>=max_batches: break\n",
        "    return np.concatenate(Z,0), np.concatenate(Y,0)\n",
        "\n",
        "# ---- visuals (SAVE + SHOW) ----\n",
        "def recon_grid(x_true_np, x_pred_np, path):\n",
        "    B = min(10, x_true_np.shape[0])\n",
        "    fig = plt.figure(figsize=(B*1.1, 2.2))\n",
        "    for i in range(B):\n",
        "        ax1 = fig.add_subplot(2,B,i+1);   ax1.imshow(x_true_np[i,0], cmap=\"gray\"); ax1.axis(\"off\")\n",
        "        ax2 = fig.add_subplot(2,B,B+i+1); ax2.imshow(x_pred_np[i,0], cmap=\"gray\"); ax2.axis(\"off\")\n",
        "    plt.tight_layout(); fig.savefig(path, dpi=150); plt.show()\n",
        "\n",
        "def loss_curve(tr, va, path, title):\n",
        "    fig = plt.figure(figsize=(8,4))\n",
        "    plt.plot(tr,'--',label=\"train\"); plt.plot(va,label=\"val\")\n",
        "    plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(title); plt.legend()\n",
        "    plt.tight_layout(); fig.savefig(path, dpi=150); plt.show()\n",
        "\n",
        "def latent_scatter(Z,y,path,title):\n",
        "    Z2 = PCA(n_components=2, random_state=SEED).fit_transform(Z) if Z.shape[1]>2 else Z\n",
        "    fig = plt.figure(figsize=(6,5))\n",
        "    sc = plt.scatter(Z2[:,0], Z2[:,1], c=y, s=6, cmap=\"tab10\")\n",
        "    plt.colorbar(sc, ticks=range(10)); plt.title(title)\n",
        "    plt.tight_layout(); fig.savefig(path, dpi=150); plt.show()\n",
        "\n",
        "# 3–4) train / eval / visualize\n",
        "def main():\n",
        "    train_loader, val_loader, test_loader = make_loaders()\n",
        "    summary=[]\n",
        "    for lat in LATS:\n",
        "        print(\"latent =\", lat)\n",
        "        m = AE(lat).to(device)\n",
        "        opt = torch.optim.Adam(m.parameters(), lr=LR)\n",
        "        trL, vaL = [], []\n",
        "        for ep in range(EPOCHS):\n",
        "            a = train_epoch(m, train_loader, opt)\n",
        "            b = eval_epoch(m, val_loader)\n",
        "            trL.append(a); vaL.append(b)\n",
        "            print(\"epoch\", ep+1, \"train_loss=\", round(a,4), \"val_loss=\", round(b,4))\n",
        "        test_mse = eval_epoch(m, test_loader); summary.append((lat, test_mse))\n",
        "        # recon grid\n",
        "        x_true,_ = next(iter(test_loader)); x_true=x_true.to(device)\n",
        "        with torch.no_grad(): x_pred,_ = m(x_true)\n",
        "        recon_grid(x_true.cpu().numpy(), x_pred.detach().cpu().numpy(), f\"fashion_recon_lat{lat}.png\")\n",
        "        # loss curve\n",
        "        loss_curve(trL, vaL, f\"fashion_loss_lat{lat}.png\", f\"Loss (latent={lat})\")\n",
        "        # latent scatter\n",
        "        Z,y = collect_latents(m, test_loader, 8)\n",
        "        latent_scatter(Z,y,f\"fashion_latent_lat{lat}.png\", f\"Latent (latent={lat})\")\n",
        "        print(\"test_mse =\", round(test_mse,4))\n",
        "    print(\"Summary (test MSE):\", [(l, round(m,4)) for l,m in summary])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}